{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "matmul.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mivzwnO2vua0",
        "colab_type": "text"
      },
      "source": [
        "## Why bottom-up approach?\n",
        "\n",
        "1. Experiment\n",
        "2. Understand it by creating it\n",
        "3. Tweak everything\n",
        "4. Contribute\n",
        "5. Correlate papers with code\n",
        "\n",
        "## Training\n",
        "\n",
        "1. Overfit\n",
        "2, Reduce over-fitting\n",
        "3. Visualize the inputs and outputs\n",
        "\n",
        "### How to reduce overfitting? (in order of priority)\n",
        "\n",
        "1. More data\n",
        "2. Data augmentation\n",
        "3. Generalizable architectures\n",
        "4. Regularization\n",
        "5. Reduce architecture complexity\n",
        "\n",
        "> Read papers!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbk36pC4xnWD",
        "colab_type": "text"
      },
      "source": [
        "## Steps to modern CNN\n",
        "\n",
        "**Matmul -> Relu/init -> FC forward -> FC backward -> Train loop -> Conv -> Optim -> Batch norm -> Resnet**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BnC4vLhGyKUr",
        "colab_type": "text"
      },
      "source": [
        "Build library in jupyter notebooks!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10YJgcgH2Hum",
        "colab_type": "text"
      },
      "source": [
        "## Matrix Multiplication from scratch\n",
        "\n",
        "Only modules/libraries allowed to use are :\n",
        "\n",
        "\n",
        "- Python\n",
        "- Python modules (non-DL)\n",
        "- pytorch indexable tensor, and - tensor creation (including RNGs - random number generators)\n",
        "- fastai.datasets\n",
        "\n",
        "> **exp** is the folder where the python scripts will reside once they are exported from the Jupyter notebooks.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ziiiKmeq2VZm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBpofKD01K5F",
        "colab_type": "code",
        "outputId": "35faed33-b3a8-4b7f-d808-d9fc85601913",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1QrQrPUY1NGi",
        "colab_type": "code",
        "outputId": "c9a22edf-69da-46e8-c008-e3b37cf8cbfa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "!ls 'drive/My Drive/dl'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "deep-learning-foundations.ipynb  exp  notebook2script.py  run_notebook.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d51pVEZ41gna",
        "colab_type": "code",
        "outputId": "b3bad0d9-42a1-4371-cfa0-70ed53803cb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd 'drive/My Drive/dl/'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/dl\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e29SvlQX24fn",
        "colab_type": "code",
        "outputId": "65990096-71df-472b-e5e4-e248b47f812e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/dl\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ayRzzc36i-G",
        "colab_type": "text"
      },
      "source": [
        "## To do unit tests"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XS87HtWt5Rs0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# export \n",
        "from exp.nb_00 import *\n",
        "import operator\n",
        "\n",
        "# set up a unit test function \n",
        "def test(a,b,cmp,cname=None):\n",
        "    if cname is None: cname=cmp.__name__\n",
        "    assert cmp(a,b),f\"{cname}:\\n{a}\\n{b}\"\n",
        "\n",
        "def test_eq(a,b): test(a,b,operator.eq,'==')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qsy43huq6WTF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_eq(TEST, 'test')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_H3A1ye1Ex6",
        "colab_type": "text"
      },
      "source": [
        "## Get the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqrbDU1U1GWO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# export\n",
        "from pathlib import Path\n",
        "from IPython.core.debugger import set_trace\n",
        "from fastai import datasets\n",
        "import pickle, gzip, math, torch, matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "from torch import tensor\n",
        "\n",
        "# MNIST in pickle (pkl) format\n",
        "MNIST_URL='http://deeplearning.net/data/mnist/mnist.pkl'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YH5lfFzY3mJs",
        "colab_type": "text"
      },
      "source": [
        "- In python the standard serialization version is **pickle**\n",
        "- It gives a tuple of tuples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWd6FiFy3Rgm",
        "colab_type": "code",
        "outputId": "bfa866dc-c845-40bc-a9ec-2073e4466da9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "path = datasets.download_data(MNIST_URL, ext='.gz'); path"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PosixPath('/root/.fastai/data/mnist.pkl.gz')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-HPOw5X3gmX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with gzip.open(path, 'rb') as f:\n",
        "    ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding=\"latin-1\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dBfYPIU3-7M",
        "colab_type": "code",
        "outputId": "c29196d1-5486-4817-961e-2e0e2a89f7a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "x_train, y_train, x_valid, y_valid = map(tensor, (x_train, y_train, x_valid, y_valid))\n",
        "# number of rows, columns\n",
        "n, c = x_train.shape\n",
        "x_train, x_train.shape, y_train, y_train.shape, y_train.min(), y_train.max()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
              " torch.Size([50000, 784]),\n",
              " tensor([5, 0, 4,  ..., 8, 4, 8]),\n",
              " torch.Size([50000]),\n",
              " tensor(0),\n",
              " tensor(9))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vu3kKKzo4i4N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "assert n==y_train.shape[0]==50000\n",
        "test_eq(c,28*28)\n",
        "test_eq(y_train.min(),0)\n",
        "test_eq(y_train.max(),9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0LxpedT6-4I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mpl.rcParams['image.cmap'] = 'gray'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rp4aAraq7dJX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img = x_train[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ei0qoNS57hn9",
        "colab_type": "code",
        "outputId": "ae12b778-8879-498b-8b93-82385c85a520",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "img.view(28,28).type()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'torch.FloatTensor'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUePLJh_7k4O",
        "colab_type": "code",
        "outputId": "f59e2402-b9af-4bfc-dae3-9af007ff6b0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "plt.imshow(img.view(28,28));"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQ9edu337ruE",
        "colab_type": "text"
      },
      "source": [
        "## Initial Python Model\n",
        "\n",
        "- Creating a linear model : $y=ax+b$\n",
        "- $a=weights$\n",
        "- dimensions : 784x10\n",
        "- $b=bias$\n",
        "- dimensions : 10x1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJ-SuJcS7t5K",
        "colab_type": "code",
        "outputId": "916329e4-ac8c-409f-8fb2-b19293deee17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "weights = torch.randn(784,10); weights.size()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([784, 10])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwr8cSh68bfj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bias = torch.zeros(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YeM6CdvF8he7",
        "colab_type": "text"
      },
      "source": [
        "### Matrix multiplication\n",
        "\n",
        "- We will need three loops\n",
        "- No of rows A = No of columns of B"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0g6Jv7I-8lml",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def matmul(a,b):\n",
        "    # n_rows, n_cols\n",
        "    ar,ac = a.shape\n",
        "    br,bc = b.shape\n",
        "    assert ac==br # check\n",
        "    c = torch.zeros(ar,bc) # resultant tensor/matrix\n",
        "    for i in range(ar):\n",
        "        for j in range(bc):\n",
        "            for k in range(br): # or ac\n",
        "                c[i,j] += a[i,k]*b[k,j]\n",
        "    return c"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDtpJ7KsBzSa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "m1 = x_valid[:5] # grab the first 5\n",
        "m2 = weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqi5XGSZB_VB",
        "colab_type": "code",
        "outputId": "12510172-05c2-411a-8991-bc39c7d711b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "m1.shape, m2.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([5, 784]), torch.Size([784, 10]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bI_ohMA9CLDM",
        "colab_type": "code",
        "outputId": "837dc295-51b1-4e76-9bbd-a74ffde44c20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "%time t1=matmul(m1,m2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 814 ms, sys: 0 ns, total: 814 ms\n",
            "Wall time: 819 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGppyi8dPdHu",
        "colab_type": "text"
      },
      "source": [
        "> So it took 819ms on vanilla python implementation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "enjHWUpYCzqI",
        "colab_type": "text"
      },
      "source": [
        "It takes about a minute. We can speed up!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4WpWQG_C1lw",
        "colab_type": "code",
        "outputId": "ce935721-0d54-46ea-d216-2ee2ec04608f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "t1.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5, 10])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0vcsJLCC7Dp",
        "colab_type": "code",
        "outputId": "57211d84-fb70-4742-e504-62d9fb938a7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(x_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HtP0TRkzC_f6",
        "colab_type": "text"
      },
      "source": [
        "> Its going to take a great amount of time! Python is **SLOW**\n",
        "\n",
        "- PyTorch uses A10 in the backend"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55oyPjHIDYRM",
        "colab_type": "text"
      },
      "source": [
        "### Elementwise operations\n",
        "\n",
        "- +,-,*,/,>,<,== are elementwise"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAbvoR0EDblN",
        "colab_type": "code",
        "outputId": "0d30d4eb-a204-48ec-9854-4f1bc7fb0fe3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "a = tensor([10.,6,-4])\n",
        "b = tensor([2.,8,7])\n",
        "a,b"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([10.,  6., -4.]), tensor([2., 8., 7.]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jBi7vFADqHu",
        "colab_type": "code",
        "outputId": "ca835577-d5dc-412e-caeb-b4ad1dae6231",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "a+b"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([12., 14.,  3.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTsUmUmWDwYJ",
        "colab_type": "code",
        "outputId": "5b9d7135-e8ec-4b27-c0f3-87fac7375c10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "(a<b).float().mean()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.6667)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNUk6RmID3CB",
        "colab_type": "code",
        "outputId": "0d1b985b-e03e-49c6-cc8d-6b118b046c01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "m = tensor([[1., 2, 3], [4,5,6], [7,8,9]]); m"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 2., 3.],\n",
              "        [4., 5., 6.],\n",
              "        [7., 8., 9.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-lfIPOqQD5ee",
        "colab_type": "text"
      },
      "source": [
        "### Frobenius norm\n",
        "\n",
        "$$\\parallel{}A_F\\parallel{} = (\\sum_{i,j=1}^{N}|a_{ij}|^2)^{1/2}$$\n",
        "- It is quite important\n",
        "- sum of two for loops i, j\n",
        "- We square $a_{ij}$ and add all of them and then take sqrt\n",
        "\n",
        "> Note : Or on arxiv.org, click \"Download: Other formats\" in the top right, then \"Download source\"; rename the downloaded file to end in .tgz if it doesn't already, and you should find the source there, including the equations to copy and paste."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-lfWbL3FX-b",
        "colab_type": "code",
        "outputId": "0fa8aac6-0c00-4d2d-986d-cab733e35113",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "(m*m).sum().sqrt()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(16.8819)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_eWNYsM-9Ext",
        "colab_type": "text"
      },
      "source": [
        "### Elementwise matmul"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udULOGxG9CN_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def matmul(a,b):\n",
        "    # n_rows, n_cols\n",
        "    ar,ac = a.shape\n",
        "    br,bc = b.shape\n",
        "    assert ac==br # check\n",
        "    c = torch.zeros(ar,bc) # resultant tensor/matrix\n",
        "    for i in range(ar):\n",
        "        for j in range(bc):\n",
        "            # no need for 3rd loop (k)\n",
        "            c[i,j] = (a[i,:]*b[:,j]).sum()\n",
        "    return c"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzaCLSr9-s0K",
        "colab_type": "text"
      },
      "source": [
        "- `c[i,j] = (a[i,:]*b[:,j]).sum()` runs on **C (language)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuo_AwbG9fQh",
        "colab_type": "code",
        "outputId": "53763f41-01d2-4cfe-932b-48f7575e8217",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%timeit -n 10 _=matmul(m1,m2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10 loops, best of 3: 1.57 ms per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvN-K6__9piE",
        "colab_type": "text"
      },
      "source": [
        "To check how much the speedup was"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odWoxUAH9lg6",
        "colab_type": "code",
        "outputId": "43407303-4352-485e-ed3a-260e82d45c91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "819/1.57"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "521.656050955414"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8TNV2tazPWmg",
        "colab_type": "text"
      },
      "source": [
        "> There was a 500x speedup from vanilla python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNQOZJGK_dU6",
        "colab_type": "text"
      },
      "source": [
        "To check if its right (floats slightly differ) with some level of tolerance we define a function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2ODn1sL-3a2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#export \n",
        "def near(a,b): return torch.allclose(a,b, rtol=1e-3, atol=1e-5)\n",
        "def test_near(a,b): test(a,b,near)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grOpQoLc_NZR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_near(t1, matmul(m1,m2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NcaM8KcQ_sNe",
        "colab_type": "text"
      },
      "source": [
        "## Broadcasting\n",
        "\n",
        "- Running code on python and runs near C/CUDA speeds\n",
        "- Idea comes from APL (1962)\n",
        "- The term broadcasting describes how arrays with different shapes are treated during arithmetic operations. The term broadcasting was first used by Numpy.\n",
        "- Subject to certain \n",
        "constraints, the smaller array is “broadcast” across the larger \n",
        "array so that they have compatible shapes. Broadcasting provides a \n",
        "means of vectorizing array operations so that looping occurs in C\n",
        "instead of Python. It does this without making needless copies of \n",
        "data and usually leads to efficient algorithm implementations.\n",
        "- In addition to the efficiency of broadcasting, it allows developers to write less code, which typically leads to fewer errors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2bK2PHtAZhy",
        "colab_type": "code",
        "outputId": "e4412cd0-f714-4556-c795-ae906271b580",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "a"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([10.,  6., -4.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTXBql1vAdpn",
        "colab_type": "text"
      },
      "source": [
        "### Broadcasting : Scalar (rank 0) to Vector (rank 1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krBzR9P8Aca9",
        "colab_type": "code",
        "outputId": "c23b73dc-a9dc-4145-978e-5214d7853bac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "a > 0"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 1, 0], dtype=torch.uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0sxnEFjqAmq5",
        "colab_type": "text"
      },
      "source": [
        "- Here the value 0 is broadcasted 3 times i.e. `[0, 0, 0]` and then elementwise comparison takes place.\n",
        "- A scalar is broadcasted to vector in this case\n",
        "- How are we able to do a > 0? 0 is being broadcast to have the same dimensions as a.\n",
        "- **Normalization** : For instance you can normalize our dataset by subtracting the mean (a scalar) from the entire data set (a matrix) and dividing by the standard deviation (another scalar), using broadcasting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "db7sFYciA8Wb",
        "colab_type": "code",
        "outputId": "8a441acd-cc38-4638-d178-8ea507d949a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "a + 1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([11.,  7., -3.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_DPEpoIBGwe",
        "colab_type": "code",
        "outputId": "36bf71ca-28f3-49b8-b17f-999483d08809",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "m"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 2., 3.],\n",
              "        [4., 5., 6.],\n",
              "        [7., 8., 9.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "062m9feEBHlU",
        "colab_type": "code",
        "outputId": "48af59ae-d2f4-4bd1-9b2c-90e2ae7fb8e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "2*m"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 2.,  4.,  6.],\n",
              "        [ 8., 10., 12.],\n",
              "        [14., 16., 18.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iF7cTh3tBIze",
        "colab_type": "text"
      },
      "source": [
        "> Anytime we broadcast we are operating at C/CUDA speeds not python."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ueH5zIRIBf0U",
        "colab_type": "text"
      },
      "source": [
        "### Broadcasting : Vector (rank 1) to Matrix (rank 2)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1K8MQbDGBfZk",
        "colab_type": "code",
        "outputId": "ac4e3aaa-3dba-463a-b1f1-04cbbc785a9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "c = tensor([10.,20,30]); c"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([10., 20., 30.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XeaMiEB8Bqxm",
        "colab_type": "code",
        "outputId": "d4c0d78c-a616-422a-dae4-b8def9d82cef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "m"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 2., 3.],\n",
              "        [4., 5., 6.],\n",
              "        [7., 8., 9.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sd0-vv_zBxKo",
        "colab_type": "code",
        "outputId": "7d7f19cc-f80d-4bc6-82b8-3dc1865e2460",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "c.size(), m.size()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([3]), torch.Size([3, 3]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAgOSVyKB3o2",
        "colab_type": "code",
        "outputId": "141b88ac-0c1e-4d60-ba5a-16ab00ebfcbb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "m + c"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[11., 22., 33.],\n",
              "        [14., 25., 36.],\n",
              "        [17., 28., 39.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCqA78kPCFlM",
        "colab_type": "text"
      },
      "source": [
        "So it broadcasted c into a 3x3 matrix (with repeating rows)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MuC5GtviCHhj",
        "colab_type": "code",
        "outputId": "06a5d686-81f9-4e31-c11d-9f5276331d2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "c + m"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[11., 22., 33.],\n",
              "        [14., 25., 36.],\n",
              "        [17., 28., 39.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "055_w854CX8Q",
        "colab_type": "text"
      },
      "source": [
        "> We don't really copy the rows, but it looks as if we did. In fact, the rows are given a stride of 0.\n",
        "\n",
        "Lets see what c would look like when broadcasted to m,"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWELzXv7CZ6x",
        "colab_type": "code",
        "outputId": "d7bf3f0e-fea8-46c8-eaba-c3cee9b0bfb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "t = c.expand_as(m); t"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[10., 20., 30.],\n",
              "        [10., 20., 30.],\n",
              "        [10., 20., 30.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TB5HCJ-iCnkE",
        "colab_type": "code",
        "outputId": "a89ac9b2-338d-4f40-ac15-3ff861852226",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "m + t"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[11., 22., 33.],\n",
              "        [14., 25., 36.],\n",
              "        [17., 28., 39.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ga5xSNPeCrYZ",
        "colab_type": "text"
      },
      "source": [
        "Lets check the storage,"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILZ8EyzxCuMm",
        "colab_type": "code",
        "outputId": "532cb61d-55d9-49ee-841f-590dbe6d7e44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "t.storage()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              " 10.0\n",
              " 20.0\n",
              " 30.0\n",
              "[torch.FloatStorage of size 3]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1wKTp2-CxX6",
        "colab_type": "code",
        "outputId": "be7eb326-069c-4471-d751-07a31118d796",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "t.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88cUerhhC0xN",
        "colab_type": "code",
        "outputId": "64f3feb6-d386-42f7-f855-aeb3781cf2ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "t.stride()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Ux7wCYAC5go",
        "colab_type": "text"
      },
      "source": [
        "> Stride tells us that when it goes col to col it should take 1 step but from row to row it should take 0 steps through the storage!\n",
        "\n",
        "- Broadcasting gives us C-like speed with no additional memory overhead.\n",
        "- You can index with the special value [None] or use unsqueeze() to convert a 1-dimensional array into a 2-dimensional array (although one of those dimensions has value 1)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDMRWQMdI5zQ",
        "colab_type": "code",
        "outputId": "8c3f51dc-e760-4236-cb26-873e662f0f37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "c.unsqueeze(0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[10., 20., 30.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LuYQFynI9YH",
        "colab_type": "code",
        "outputId": "6b66e053-81bf-4200-fd1d-46d92df98a67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "c.unsqueeze(1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[10.],\n",
              "        [20.],\n",
              "        [30.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PfToWCNkJFmJ",
        "colab_type": "code",
        "outputId": "883d38c2-313f-4b5c-89ff-cacb5da3ec45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "m"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 2., 3.],\n",
              "        [4., 5., 6.],\n",
              "        [7., 8., 9.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKeYae_UJGNA",
        "colab_type": "code",
        "outputId": "6cab2b44-64b4-47f2-f2d5-3bfc419f4941",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "c.shape, c.unsqueeze(0).shape,c.unsqueeze(1).shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([3]), torch.Size([1, 3]), torch.Size([3, 1]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xoGS2-D6JP-J",
        "colab_type": "code",
        "outputId": "7b1418e8-2f3e-4af4-f40e-115a459e3ceb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "c.shape, c[None].shape,c[:,None].shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([3]), torch.Size([1, 3]), torch.Size([3, 1]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2W0dG5qDJYCj",
        "colab_type": "text"
      },
      "source": [
        "> You can always skip trailling ':'s. And '...' means 'all preceding dimensions'. Useful if the rank of the tensor would vary.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suaI0uLqXBA3",
        "colab_type": "code",
        "outputId": "de74c4f6-b59e-4280-fe81-6395bdf48baf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "c[None].shape, c[...,None].shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 3]), torch.Size([3, 1]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFKh2c3bJ3Ww",
        "colab_type": "code",
        "outputId": "35e673d2-ccfe-4c4d-e733-d8e903d8be37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "c[:, None].expand_as(m)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[10., 10., 10.],\n",
              "        [20., 20., 20.],\n",
              "        [30., 30., 30.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9g71voD8KIja",
        "colab_type": "text"
      },
      "source": [
        "- Its getting broadcasted along the columns instead of rows "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15ACSEC8KRiz",
        "colab_type": "code",
        "outputId": "9918693a-1e7c-4d17-9e5e-1580860ff04e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "m + c[:, None]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[11., 12., 13.],\n",
              "        [24., 25., 26.],\n",
              "        [37., 38., 39.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCAOJ2SVK4gV",
        "colab_type": "code",
        "outputId": "d24c6c6f-aabd-4662-e5bd-d2c13f43a308",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "c[:, None]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[10.],\n",
              "        [20.],\n",
              "        [30.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTbBjf8ELX47",
        "colab_type": "code",
        "outputId": "3b860e55-5e50-46a5-c291-cdfb2f08d38f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "c[None,...]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[10., 20., 30.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FcskSVJOK93c",
        "colab_type": "text"
      },
      "source": [
        "### Matmul with broadcasting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ee_f6TViLs4f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def matmul(a,b):\n",
        "    # n_rows, n_cols\n",
        "    ar,ac = a.shape\n",
        "    br,bc = b.shape\n",
        "    assert ac==br # check\n",
        "    c = torch.zeros(ar,bc) # resultant tensor/matrix\n",
        "    for i in range(ar):\n",
        "        # no need for 2nd loop (j)\n",
        "        # alternatively\n",
        "        # c[i] = (a[i, :, None]*b).sum(0)\n",
        "        c[i] = (a[i].unsqueeze(-1) * b).sum(dim=0)\n",
        "    return c"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlwrcuQaX2uW",
        "colab_type": "code",
        "outputId": "5a394922-630d-47a0-d1d6-e79b3bdf395d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%timeit -n 10 _=matmul(m1,m2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10 loops, best of 3: 298 µs per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FldmXKgnPMgP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3ca8dd96-bb73-44c1-facc-d623e6af2a4e"
      },
      "source": [
        "819000/298"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2748.3221476510066"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZMaQdQlvPPcA",
        "colab_type": "text"
      },
      "source": [
        "> 2700x speedup from vanilla python!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-TRqTBuZFOD",
        "colab_type": "text"
      },
      "source": [
        "### Broadcasting rules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iph96KC5ZL5H",
        "colab_type": "code",
        "outputId": "d48d90c6-f0f1-4ed9-da6d-7d11db8f95b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "c[None, :].shape # inserting a preceding axis"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16XhorAMZQ61",
        "colab_type": "code",
        "outputId": "eb44c75d-90f6-49cc-f19a-f826cc5dd7dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "c[:, None].shape # inserting a leading axis"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "772TC7ZeZXeV",
        "colab_type": "code",
        "outputId": "8b0fbebb-60f9-4730-eead-e7dcf8403b58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "c[None, :] * c[:, None]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[100., 200., 300.],\n",
              "        [200., 400., 600.],\n",
              "        [300., 600., 900.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IE9TI14MZqb-",
        "colab_type": "text"
      },
      "source": [
        "Broadcasts the first one to match the second's shape and vice versa."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFVl4co4ZvKN",
        "colab_type": "code",
        "outputId": "e363bff7-94fc-41b3-b40a-2da804b07f7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "c[None] > c[:,None]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0, 1, 1],\n",
              "        [0, 0, 1],\n",
              "        [0, 0, 0]], dtype=torch.uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skUyo1lfZ8Ge",
        "colab_type": "text"
      },
      "source": [
        "> \n",
        "\n",
        "When operating on two arrays/tensors, Numpy/PyTorch compares their shapes element-wise. It starts with the trailing dimensions, and works its way forward. Two dimensions are compatible when\n",
        "\n",
        "- they are equal, or\n",
        "- one of them is 1, in which case that dimension is broadcasted to make it the same size\n",
        "\n",
        "Arrays do not need to have the same number of dimensions. For example, if you have a `256*256*3` array of RGB values, and you want to scale each color in the image by a different value, you can multiply the image by a one-dimensional array with 3 values. Lining up the sizes of the trailing axes of these arrays according to the broadcast rules, shows that they are compatible:\n",
        "\n",
        "Image  (3d array): 256 x 256 x 3\n",
        "Scale  (1d array):             3\n",
        "Result (3d array): 256 x 256 x 3\n",
        "\n",
        "The numpy documentation includes several examples of what dimensions can and can not be broadcast together.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZt4Nk0qcaZ3",
        "colab_type": "text"
      },
      "source": [
        "### Einstein Summation\n",
        "\n",
        "\n",
        "\n",
        "Einstein summation (einsum) is a compact representation for combining products and sums in a general way. From the numpy docs:\n",
        "\n",
        "\"The subscripts string is a comma-separated list of subscript labels, where each label refers to a dimension of the corresponding operand. Whenever a label is repeated it is summed, so np.einsum('i,i', a, b) is equivalent to np.inner(a,b). If a label appears only once, it is not summed, so np.einsum('i', a) produces a view of a with no changes.\"\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9OMPtmbcqSy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# How we convert to einsum notation :\n",
        "# 1. c[i,j] += a[i,k] * b[k,j]\n",
        "# 2. a[i,k] * b[k,j] -> c[i,j]\n",
        "# 3. ik,kj->ij\n",
        "\n",
        "def matmul(a,b): return torch.einsum('ik,kj->ij', a, b)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aILBNPGJe9jJ",
        "colab_type": "text"
      },
      "source": [
        "- no of inputs delimited by comma\n",
        "- rank of each input is equal to number of inputs i.e. ik, kj abd ij are all "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xjKTxbc6NAX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "bc093346-1e90-4810-f352-bd61ca6c7a7f"
      },
      "source": [
        "%timeit -n 10 _=matmul(m1,m2)"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The slowest run took 83.14 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
            "10 loops, best of 3: 46.9 µs per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9aBDZBd6VsM",
        "colab_type": "text"
      },
      "source": [
        "> It took just **`46.9 µs`**!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGtNqrKS8HRn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f1137cb1-efcb-4e42-a3fa-31db64bd4ade"
      },
      "source": [
        "885000/46.9"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18869.93603411514"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhISs7Gd9EOC",
        "colab_type": "text"
      },
      "source": [
        "> Its 18x faster than vanilla python"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0cYEvRo48MlW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_near(t1, matmul(m1,m2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbtsfY_u8_d9",
        "colab_type": "text"
      },
      "source": [
        "### PyTorch op"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ol-dKvCY9Jey",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "1e8a6b68-3cfb-4d5a-cbfe-e88f63556ebd"
      },
      "source": [
        "%timeit -n 10 t2 = m1.matmul(m2)"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The slowest run took 83.12 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
            "10 loops, best of 3: 9.27 µs per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tek5CNDT9vb2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "427ef480-1b92-4c31-c3dc-16ee083b0353"
      },
      "source": [
        "819000/9.27"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "88349.5145631068"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "grGVlrwQ95Kk",
        "colab_type": "text"
      },
      "source": [
        "> Its 88x faster than python now!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PgX_iL-q-J51",
        "colab_type": "text"
      },
      "source": [
        "- BLAS : Basic linear algebra subprograms\n",
        "- PyTorch pushes to BLAS\n",
        "- Nvidia's version : CuBLAS\n",
        "- Intel's version : MKL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSaZBQZc_ObL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# @ is an operand used for matrix multiplication \n",
        "t2 = m1@m2 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtJPZYXe_SMz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_near(t1,t2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJEdar-OJ5H1",
        "colab_type": "text"
      },
      "source": [
        "### Exporting .ipynb to .py scripts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFdylMqVJf1f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install fire\n",
        "!python notebook2script.py matmul.ipynb"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}